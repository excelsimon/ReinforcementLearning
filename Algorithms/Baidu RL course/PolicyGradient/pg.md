# Lesson 4 ç­–ç•¥æ¢¯åº¦æ–¹æ³•æ±‚è§£RLâ€”â€”Policy Gradient

## 1. Policy Gradientç®€ä»‹
* åœ¨å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œæœ‰ä¸¤å¤§ç±»æ–¹æ³•ï¼Œä¸€ç§åŸºäºå€¼ï¼ˆ`Value-based`ï¼‰ï¼Œä¸€ç§åŸºäºç­–ç•¥ï¼ˆ`Policy-based`ï¼‰
    * `Value-based`çš„ç®—æ³•çš„å…¸å‹ä»£è¡¨ä¸º`Q-learning`å’Œ`SARSA`ï¼Œå°†`Q`å‡½æ•°ä¼˜åŒ–åˆ°æœ€ä¼˜ï¼Œå†æ ¹æ®`Q`å‡½æ•°å–æœ€ä¼˜ç­–ç•¥ã€‚
    * `Policy-based`çš„ç®—æ³•çš„å…¸å‹ä»£è¡¨ä¸º`Policy Gradient`ï¼Œç›´æ¥ä¼˜åŒ–ç­–ç•¥å‡½æ•°ã€‚
* é‡‡ç”¨ç¥ç»ç½‘ç»œæ‹Ÿåˆç­–ç•¥å‡½æ•°ï¼Œéœ€è®¡ç®—ç­–ç•¥æ¢¯åº¦ç”¨äºä¼˜åŒ–ç­–ç•¥ç½‘ç»œã€‚
    * ä¼˜åŒ–çš„ç›®æ ‡æ˜¯åœ¨ç­–ç•¥`Ï€(s,a)`çš„æœŸæœ›å›æŠ¥ï¼šæ‰€æœ‰çš„è½¨è¿¹è·å¾—çš„å›æŠ¥`R`ä¸å¯¹åº”çš„è½¨è¿¹å‘ç”Ÿæ¦‚ç‡`p`çš„åŠ æƒå’Œï¼Œå½“Nè¶³å¤Ÿå¤§æ—¶ï¼Œå¯é€šè¿‡é‡‡æ ·Nä¸ªEpisodeæ±‚å¹³å‡çš„æ–¹å¼è¿‘ä¼¼è¡¨è¾¾ã€‚
    
    ![](https://ai-studio-static-online.cdn.bcebos.com/eb184ddf8dcc4dc3b528a105f8d8e3ea6487d4905bc04cdebd7725f2d6a2752f)
    
    * ä¼˜åŒ–ç›®æ ‡å¯¹å‚æ•°`Î¸`æ±‚å¯¼åå¾—åˆ°ç­–ç•¥æ¢¯åº¦ï¼š
    
    ![](https://ai-studio-static-online.cdn.bcebos.com/326d8abe040347cea25e4c0be3e09015e85cb818a02c445483381540ab1d238c)
    
    
## 2. Policy Gradientå®è·µâ€”â€”REINFORCEç®—æ³•
* ä½¿ç”¨`REINFORCE`è§£å†³ è¿ç»­æ§åˆ¶ç‰ˆæœ¬çš„`CartPole`é—®é¢˜ï¼Œå‘å°è½¦æä¾›æ¨åŠ›ä½¿å¾—è½¦ä¸Šçš„æ‘†æ†å€’ç«‹èµ·æ¥ã€‚

### Step1 å®‰è£…ä¾èµ–


```python
!pip uninstall -y parl  # è¯´æ˜ï¼šAIStudioé¢„è£…çš„parlç‰ˆæœ¬å¤ªè€ï¼Œå®¹æ˜“è·Ÿå…¶ä»–åº“äº§ç”Ÿå…¼å®¹æ€§å†²çªï¼Œå»ºè®®å…ˆå¸è½½
!pip uninstall -y pandas scikit-learn # æç¤ºï¼šåœ¨AIStudioä¸­å¸è½½è¿™ä¸¤ä¸ªåº“å†import parlå¯é¿å…warningæç¤ºï¼Œä¸å¸è½½ä¹Ÿä¸å½±å“parlçš„ä½¿ç”¨

!pip install gym
!pip install paddlepaddle==1.6.3
!pip install parl==1.3.1

# è¯´æ˜ï¼šå®‰è£…æ—¥å¿—ä¸­å‡ºç°ä¸¤æ¡çº¢è‰²çš„å…³äº paddlehub å’Œ visualdl çš„ ERROR ä¸parlæ— å…³ï¼Œå¯ä»¥å¿½ç•¥ï¼Œä¸å½±å“ä½¿ç”¨
```


```python
# æ£€æŸ¥ä¾èµ–åŒ…ç‰ˆæœ¬æ˜¯å¦æ­£ç¡®
!pip list | grep paddlepaddle
!pip list | grep parl
```

### Step2 å¯¼å…¥ä¾èµ–


```python
import os
import gym
import numpy as np

import paddle.fluid as fluid
import parl
from parl import layers
from parl.utils import logger

```

### Step3 è®¾ç½®è¶…å‚æ•°


```python
LEARNING_RATE = 1e-3
```

### Step4 æ­å»ºModelã€Algorithmã€Agentæ¶æ„
* `Agent`æŠŠäº§ç”Ÿçš„æ•°æ®ä¼ ç»™`algorithm`ï¼Œ`algorithm`æ ¹æ®`model`çš„æ¨¡å‹ç»“æ„è®¡ç®—å‡º`Loss`ï¼Œä½¿ç”¨`SGD`æˆ–è€…å…¶ä»–ä¼˜åŒ–å™¨ä¸æ–­çš„ä¼˜åŒ–ï¼Œ`PARL`è¿™ç§æ¶æ„å¯ä»¥å¾ˆæ–¹ä¾¿çš„åº”ç”¨åœ¨å„ç±»æ·±åº¦å¼ºåŒ–å­¦ä¹ é—®é¢˜ä¸­ã€‚

#### ï¼ˆ1ï¼‰Model
`Model`ç”¨æ¥å®šä¹‰å‰å‘(`Forward`)ç½‘ç»œï¼Œç”¨æˆ·å¯ä»¥è‡ªç”±çš„å®šåˆ¶è‡ªå·±çš„ç½‘ç»œç»“æ„ã€‚


```python
class Model(parl.Model):
    def __init__(self, act_dim):
        act_dim = act_dim
        hid1_size = act_dim * 10

        self.fc1 = layers.fc(size=hid1_size, act='tanh')
        self.fc2 = layers.fc(size=act_dim, act='softmax')

    def forward(self, obs):  # å¯ç›´æ¥ç”¨ model = Model(5); model(obs)è°ƒç”¨
        out = self.fc1(obs)
        out = self.fc2(out)
        return out

```

#### ï¼ˆ2ï¼‰Algorithm
* `Algorithm` å®šä¹‰äº†å…·ä½“çš„ç®—æ³•æ¥æ›´æ–°å‰å‘ç½‘ç»œ(`Model`)ï¼Œä¹Ÿå°±æ˜¯é€šè¿‡å®šä¹‰æŸå¤±å‡½æ•°æ¥æ›´æ–°`Model`ï¼Œå’Œç®—æ³•ç›¸å…³çš„è®¡ç®—éƒ½æ”¾åœ¨`algorithm`ä¸­ã€‚


```python
# from parl.algorithms import PolicyGradient # ä¹Ÿå¯ä»¥ç›´æ¥ä»parlåº“ä¸­å¯¼å…¥PolicyGradientç®—æ³•ï¼Œæ— éœ€é‡å¤å†™ç®—æ³•

class PolicyGradient(parl.Algorithm):
    def __init__(self, model, lr=None):
        """ Policy Gradient algorithm
        
        Args:
            model (parl.Model): policyçš„å‰å‘ç½‘ç»œ.
            lr (float): å­¦ä¹ ç‡.
        """

        self.model = model
        assert isinstance(lr, float)
        self.lr = lr

    def predict(self, obs):
        """ ä½¿ç”¨policy modelé¢„æµ‹è¾“å‡ºçš„åŠ¨ä½œæ¦‚ç‡
        """
        return self.model(obs)

    def learn(self, obs, action, reward):
        """ ç”¨policy gradient ç®—æ³•æ›´æ–°policy model
        """
        act_prob = self.model(obs)  # è·å–è¾“å‡ºåŠ¨ä½œæ¦‚ç‡
        # log_prob = layers.cross_entropy(act_prob, action) # äº¤å‰ç†µ
        log_prob = layers.reduce_sum(
            -1.0 * layers.log(act_prob) * layers.one_hot(
                action, act_prob.shape[1]),
            dim=1)
        cost = log_prob * reward
        cost = layers.reduce_mean(cost)

        optimizer = fluid.optimizer.Adam(self.lr)
        optimizer.minimize(cost)
        return cost

```

#### ï¼ˆ3ï¼‰Agent
* `Agent`è´Ÿè´£ç®—æ³•ä¸ç¯å¢ƒçš„äº¤äº’ï¼Œåœ¨äº¤äº’è¿‡ç¨‹ä¸­æŠŠç”Ÿæˆçš„æ•°æ®æä¾›ç»™`Algorithm`æ¥æ›´æ–°æ¨¡å‹(`Model`)ï¼Œæ•°æ®çš„é¢„å¤„ç†æµç¨‹ä¹Ÿä¸€èˆ¬å®šä¹‰åœ¨è¿™é‡Œã€‚


```python
class Agent(parl.Agent):
    def __init__(self, algorithm, obs_dim, act_dim):
        self.obs_dim = obs_dim
        self.act_dim = act_dim
        super(Agent, self).__init__(algorithm)

    def build_program(self):
        self.pred_program = fluid.Program()
        self.learn_program = fluid.Program()

        with fluid.program_guard(self.pred_program):  # æ­å»ºè®¡ç®—å›¾ç”¨äº é¢„æµ‹åŠ¨ä½œï¼Œå®šä¹‰è¾“å…¥è¾“å‡ºå˜é‡
            obs = layers.data(
                name='obs', shape=[self.obs_dim], dtype='float32')
            self.act_prob = self.alg.predict(obs)

        with fluid.program_guard(
                self.learn_program):  # æ­å»ºè®¡ç®—å›¾ç”¨äº æ›´æ–°policyç½‘ç»œï¼Œå®šä¹‰è¾“å…¥è¾“å‡ºå˜é‡
            obs = layers.data(
                name='obs', shape=[self.obs_dim], dtype='float32')
            act = layers.data(name='act', shape=[1], dtype='int64')
            reward = layers.data(name='reward', shape=[], dtype='float32')
            self.cost = self.alg.learn(obs, act, reward)

    def sample(self, obs):
        obs = np.expand_dims(obs, axis=0)  # å¢åŠ ä¸€ç»´ç»´åº¦
        act_prob = self.fluid_executor.run(
            self.pred_program,
            feed={'obs': obs.astype('float32')},
            fetch_list=[self.act_prob])[0]
        act_prob = np.squeeze(act_prob, axis=0)  # å‡å°‘ä¸€ç»´ç»´åº¦
        act = np.random.choice(range(self.act_dim), p=act_prob)  # æ ¹æ®åŠ¨ä½œæ¦‚ç‡é€‰å–åŠ¨ä½œ
        return act

    def predict(self, obs):
        obs = np.expand_dims(obs, axis=0)
        act_prob = self.fluid_executor.run(
            self.pred_program,
            feed={'obs': obs.astype('float32')},
            fetch_list=[self.act_prob])[0]
        act_prob = np.squeeze(act_prob, axis=0)
        act = np.argmax(act_prob)  # æ ¹æ®åŠ¨ä½œæ¦‚ç‡é€‰æ‹©æ¦‚ç‡æœ€é«˜çš„åŠ¨ä½œ
        return act

    def learn(self, obs, act, reward):
        act = np.expand_dims(act, axis=-1)
        feed = {
            'obs': obs.astype('float32'),
            'act': act.astype('int64'),
            'reward': reward.astype('float32')
        }
        cost = self.fluid_executor.run(
            self.learn_program, feed=feed, fetch_list=[self.cost])[0]
        return cost

```

### Step 5 Training && Testï¼ˆè®­ç»ƒ&&æµ‹è¯•ï¼‰


```python
def run_episode(env, agent):
    obs_list, action_list, reward_list = [], [], []
    obs = env.reset()
    while True:
        obs_list.append(obs)
        action = agent.sample(obs) # é‡‡æ ·åŠ¨ä½œ
        action_list.append(action)

        obs, reward, done, info = env.step(action)
        reward_list.append(reward)

        if done:
            break
    return obs_list, action_list, reward_list

# è¯„ä¼° agent, è·‘ 5 ä¸ªepisodeï¼Œæ€»rewardæ±‚å¹³å‡
def evaluate(env, agent, render=False):
    eval_reward = []
    for i in range(5):
        obs = env.reset()
        episode_reward = 0
        while True:
            action = agent.predict(obs) # é€‰å–æœ€ä¼˜åŠ¨ä½œ
            obs, reward, isOver, _ = env.step(action)
            episode_reward += reward
            if render:
                env.render()
            if isOver:
                break
        eval_reward.append(episode_reward)
    return np.mean(eval_reward)

```

### Step6 åˆ›å»ºç¯å¢ƒå’ŒAgentï¼Œå¯åŠ¨è®­ç»ƒï¼Œä¿å­˜æ¨¡å‹


```python
# æ ¹æ®ä¸€ä¸ªepisodeçš„æ¯ä¸ªstepçš„rewardåˆ—è¡¨ï¼Œè®¡ç®—æ¯ä¸€ä¸ªStepçš„Gt
def calc_reward_to_go(reward_list, gamma=1.0):
    for i in range(len(reward_list) - 2, -1, -1):
        # G_t = r_t + Î³Â·r_t+1 + ... = r_t + Î³Â·G_t+1
        reward_list[i] += gamma * reward_list[i + 1]  # Gt
    return np.array(reward_list)


# åˆ›å»ºç¯å¢ƒ
env = gym.make('CartPole-v0')
obs_dim = env.observation_space.shape[0]
act_dim = env.action_space.n
logger.info('obs_dim {}, act_dim {}'.format(obs_dim, act_dim))

# æ ¹æ®parlæ¡†æ¶æ„å»ºagent
model = Model(act_dim=act_dim)
alg = PolicyGradient(model, lr=LEARNING_RATE)
agent = Agent(alg, obs_dim=obs_dim, act_dim=act_dim)

# åŠ è½½æ¨¡å‹
# if os.path.exists('./model.ckpt'):
#     agent.restore('./model.ckpt')
#     run_episode(env, agent, train_or_test='test', render=True)
#     exit()

for i in range(1000):
    obs_list, action_list, reward_list = run_episode(env, agent)
    if i % 10 == 0:
        logger.info("Episode {}, Reward Sum {}.".format(
            i, sum(reward_list)))

    batch_obs = np.array(obs_list)
    batch_action = np.array(action_list)
    batch_reward = calc_reward_to_go(reward_list)

    agent.learn(batch_obs, batch_action, batch_reward)
    if (i + 1) % 100 == 0:
        total_reward = evaluate(env, agent, render=False) # render=True æŸ¥çœ‹æ¸²æŸ“æ•ˆæœï¼Œéœ€è¦åœ¨æœ¬åœ°è¿è¡Œï¼ŒAIStudioæ— æ³•æ˜¾ç¤º
        logger.info('Test reward: {}'.format(total_reward))

# ä¿å­˜æ¨¡å‹åˆ°æ–‡ä»¶ ./model.ckpt
agent.save('./model.ckpt')

```

    [32m[06-09 23:30:14 MainThread @<ipython-input-9-67de6cabb2c8>:13][0m obs_dim 4, act_dim 2
    [32m[06-09 23:30:14 MainThread @machine_info.py:84][0m Cannot find available GPU devices, using CPU now.
    [32m[06-09 23:30:14 MainThread @machine_info.py:84][0m Cannot find available GPU devices, using CPU now.
    [32m[06-09 23:30:14 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 0, Reward Sum 28.0.
    [32m[06-09 23:30:15 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 10, Reward Sum 23.0.
    [32m[06-09 23:30:15 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 20, Reward Sum 68.0.
    [32m[06-09 23:30:16 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 30, Reward Sum 22.0.
    [32m[06-09 23:30:16 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 40, Reward Sum 10.0.
    [32m[06-09 23:30:17 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 50, Reward Sum 18.0.
    [32m[06-09 23:30:17 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 60, Reward Sum 19.0.
    [32m[06-09 23:30:18 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 70, Reward Sum 49.0.
    [32m[06-09 23:30:19 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 80, Reward Sum 76.0.
    [32m[06-09 23:30:20 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 90, Reward Sum 35.0.
    [32m[06-09 23:30:21 MainThread @<ipython-input-9-67de6cabb2c8>:39][0m Test reward: 61.0
    [32m[06-09 23:30:21 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 100, Reward Sum 30.0.
    [32m[06-09 23:30:21 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 110, Reward Sum 42.0.
    [32m[06-09 23:30:22 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 120, Reward Sum 36.0.
    [32m[06-09 23:30:23 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 130, Reward Sum 29.0.
    [32m[06-09 23:30:24 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 140, Reward Sum 38.0.
    [32m[06-09 23:30:24 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 150, Reward Sum 96.0.
    [32m[06-09 23:30:25 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 160, Reward Sum 13.0.
    [32m[06-09 23:30:26 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 170, Reward Sum 51.0.
    [32m[06-09 23:30:27 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 180, Reward Sum 31.0.
    [32m[06-09 23:30:27 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 190, Reward Sum 36.0.
    [32m[06-09 23:30:29 MainThread @<ipython-input-9-67de6cabb2c8>:39][0m Test reward: 51.6
    [32m[06-09 23:30:29 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 200, Reward Sum 29.0.
    [32m[06-09 23:30:30 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 210, Reward Sum 75.0.
    [32m[06-09 23:30:31 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 220, Reward Sum 78.0.
    [32m[06-09 23:30:32 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 230, Reward Sum 35.0.
    [32m[06-09 23:30:32 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 240, Reward Sum 22.0.
    [32m[06-09 23:30:33 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 250, Reward Sum 37.0.
    [32m[06-09 23:30:34 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 260, Reward Sum 105.0.
    [32m[06-09 23:30:35 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 270, Reward Sum 22.0.
    [32m[06-09 23:30:36 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 280, Reward Sum 49.0.
    [32m[06-09 23:30:37 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 290, Reward Sum 116.0.
    [32m[06-09 23:30:39 MainThread @<ipython-input-9-67de6cabb2c8>:39][0m Test reward: 125.8
    [32m[06-09 23:30:39 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 300, Reward Sum 61.0.
    [32m[06-09 23:30:41 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 310, Reward Sum 48.0.
    [32m[06-09 23:30:41 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 320, Reward Sum 50.0.
    [32m[06-09 23:30:43 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 330, Reward Sum 52.0.
    [32m[06-09 23:30:44 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 340, Reward Sum 72.0.
    [32m[06-09 23:30:45 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 350, Reward Sum 107.0.
    [32m[06-09 23:30:46 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 360, Reward Sum 41.0.
    [32m[06-09 23:30:48 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 370, Reward Sum 91.0.
    [32m[06-09 23:30:49 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 380, Reward Sum 64.0.
    [32m[06-09 23:30:50 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 390, Reward Sum 87.0.
    [32m[06-09 23:30:53 MainThread @<ipython-input-9-67de6cabb2c8>:39][0m Test reward: 172.2
    [32m[06-09 23:30:53 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 400, Reward Sum 57.0.
    [32m[06-09 23:30:54 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 410, Reward Sum 59.0.
    [32m[06-09 23:30:55 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 420, Reward Sum 56.0.
    [32m[06-09 23:30:57 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 430, Reward Sum 56.0.
    [32m[06-09 23:30:58 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 440, Reward Sum 77.0.
    [32m[06-09 23:30:59 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 450, Reward Sum 30.0.
    [32m[06-09 23:31:01 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 460, Reward Sum 68.0.
    [32m[06-09 23:31:02 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 470, Reward Sum 131.0.
    [32m[06-09 23:31:04 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 480, Reward Sum 75.0.
    [32m[06-09 23:31:06 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 490, Reward Sum 107.0.
    [32m[06-09 23:31:09 MainThread @<ipython-input-9-67de6cabb2c8>:39][0m Test reward: 200.0
    [32m[06-09 23:31:09 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 500, Reward Sum 145.0.
    [32m[06-09 23:31:12 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 510, Reward Sum 119.0.
    [32m[06-09 23:31:13 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 520, Reward Sum 18.0.
    [32m[06-09 23:31:16 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 530, Reward Sum 92.0.
    [32m[06-09 23:31:19 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 540, Reward Sum 140.0.
    [32m[06-09 23:31:21 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 550, Reward Sum 194.0.
    [32m[06-09 23:31:24 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 560, Reward Sum 34.0.
    [32m[06-09 23:31:26 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 570, Reward Sum 67.0.
    [32m[06-09 23:31:29 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 580, Reward Sum 56.0.
    [32m[06-09 23:31:31 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 590, Reward Sum 180.0.
    [32m[06-09 23:31:36 MainThread @<ipython-input-9-67de6cabb2c8>:39][0m Test reward: 200.0
    [32m[06-09 23:31:37 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 600, Reward Sum 200.0.
    [32m[06-09 23:31:39 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 610, Reward Sum 104.0.
    [32m[06-09 23:31:42 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 620, Reward Sum 21.0.
    [32m[06-09 23:31:45 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 630, Reward Sum 200.0.
    [32m[06-09 23:31:48 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 640, Reward Sum 200.0.
    [32m[06-09 23:31:51 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 650, Reward Sum 139.0.
    [32m[06-09 23:31:54 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 660, Reward Sum 200.0.
    [32m[06-09 23:31:57 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 670, Reward Sum 200.0.
    [32m[06-09 23:32:01 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 680, Reward Sum 200.0.
    [32m[06-09 23:32:04 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 690, Reward Sum 200.0.
    [32m[06-09 23:32:09 MainThread @<ipython-input-9-67de6cabb2c8>:39][0m Test reward: 200.0
    [32m[06-09 23:32:09 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 700, Reward Sum 141.0.
    [32m[06-09 23:32:12 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 710, Reward Sum 139.0.
    [32m[06-09 23:32:15 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 720, Reward Sum 140.0.
    [32m[06-09 23:32:18 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 730, Reward Sum 130.0.
    [32m[06-09 23:32:21 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 740, Reward Sum 160.0.
    [32m[06-09 23:32:24 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 750, Reward Sum 25.0.
    [32m[06-09 23:32:28 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 760, Reward Sum 170.0.
    [32m[06-09 23:32:32 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 770, Reward Sum 200.0.
    [32m[06-09 23:32:36 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 780, Reward Sum 200.0.
    [32m[06-09 23:32:39 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 790, Reward Sum 103.0.
    [32m[06-09 23:32:45 MainThread @<ipython-input-9-67de6cabb2c8>:39][0m Test reward: 200.0
    [32m[06-09 23:32:45 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 800, Reward Sum 185.0.
    [32m[06-09 23:32:49 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 810, Reward Sum 200.0.
    [32m[06-09 23:32:52 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 820, Reward Sum 95.0.
    [32m[06-09 23:32:55 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 830, Reward Sum 98.0.
    [32m[06-09 23:32:59 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 840, Reward Sum 200.0.
    [32m[06-09 23:33:03 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 850, Reward Sum 200.0.
    [32m[06-09 23:33:07 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 860, Reward Sum 166.0.
    [32m[06-09 23:33:11 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 870, Reward Sum 200.0.
    [32m[06-09 23:33:14 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 880, Reward Sum 163.0.
    [32m[06-09 23:33:18 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 890, Reward Sum 200.0.
    [32m[06-09 23:33:23 MainThread @<ipython-input-9-67de6cabb2c8>:39][0m Test reward: 200.0
    [32m[06-09 23:33:24 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 900, Reward Sum 165.0.
    [32m[06-09 23:33:28 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 910, Reward Sum 200.0.
    [32m[06-09 23:33:31 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 920, Reward Sum 200.0.
    [32m[06-09 23:33:34 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 930, Reward Sum 38.0.
    [32m[06-09 23:33:38 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 940, Reward Sum 146.0.
    [32m[06-09 23:33:41 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 950, Reward Sum 192.0.
    [32m[06-09 23:33:45 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 960, Reward Sum 152.0.
    [32m[06-09 23:33:48 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 970, Reward Sum 200.0.
    [32m[06-09 23:33:52 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 980, Reward Sum 200.0.
    [32m[06-09 23:33:56 MainThread @<ipython-input-9-67de6cabb2c8>:30][0m Episode 990, Reward Sum 160.0.
    [32m[06-09 23:34:01 MainThread @<ipython-input-9-67de6cabb2c8>:39][0m Test reward: 200.0

