{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 新手入门第一课——什么是深度学习？\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/60ba91a3d2c4427d82b933b25e490275e993d3e75f3149269a6d07efd3ff2067)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "大家好，欢迎来到新手入门课程，在这里我会带领大家从一个完全不懂深度学习的小白，通过学习本课程后，能够了解基本的深度学习概念，熟悉必备的数序基础知识，学会常见的编程工具Python，并掌握实用的深度学习框架PaddlePaddle。可能看到本课程的你并不了解什么是深度学习，那么就让我们从第一课开始把——什么是深度学习？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 一、深度学习的发展历程\n",
    "\n",
    "## 1.1 Turing Testing (图灵测试)\n",
    "\n",
    "图灵测试是人工智能是否真正能够成功的一个标准，“计算机科学之父”、“人工智能之父”英国数学家图灵在1950年的论文《机器会思考吗》中提出了图灵测试的概念。即把一个人和一台计算机分别放在两个隔离的房间中，房间外的一个人同时询问人和计算机相同的问题，如果房间外的人无法分别哪个是人，哪个是计算机，就能够说明计算机具有人工智能。\n",
    "\n",
    "\n",
    "## 1.2 医学上的发现\n",
    "\n",
    "1981年的诺贝尔将颁发给了David Hubel和Torsten Wiesel，以及Roger Sperry。他们发现了**人的视觉系统处理信息是分级的**。 \n",
    "\n",
    "从视网膜（Retina）出发，经过低级的V1区提取边缘特征，到V2区的基本形状或目标的局部，再到高层的整个目标（如判定为一张人脸），以及到更高层的PFC（前额叶皮层）进行分类判断等。也就是说**高层的特征是低层特征的组合，从低层到高层的特征表达越来越抽象和概念化，也即越来越能表现语义或者意图**。\n",
    "\n",
    "\n",
    "> 边缘特征 —–> 基本形状和目标的局部特征——>整个目标 \n",
    "这个过程其实和我们的常识是相吻合的，因为复杂的图形，往往就是由一些基本结构组合而成的。同时我们还可以看出：大脑是一个深度架构，认知过程也是深度的。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/14ba02554a4e48649332f4415341aab2cd94c6753c624265a16a8918498e6d2a)\n",
    "人脑神经元示意图\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/8e35b368c84540bdbc29beaa2d78a29466801b7e43b146cda87087a117abce3a)\n",
    "计算机识别图像的过程\n",
    "\n",
    "\n",
    "## 1.3 Deep Learning的出现\n",
    "\n",
    "> 低层次特征 - - - - (组合) - - ->抽象的高层特征\n",
    "\n",
    "深度学习，恰恰就是通过组合低层特征形成更加抽象的高层特征（或属性类别）。例如，在计算机视觉领域，深度学习算法从原始图像去学习得到一个低层次表达，例如边缘检测器、小波滤波器等，然后在这些低层次表达的基础上，通过线性或者非线性组合，来获得一个高层次的表达。此外，不仅图像存在这个规律，声音也是类似的。比如，研究人员从某个声音库中通过算法自动发现了20种基本的声音结构，其余的声音都可以由这20种基本结构来合成！\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "# 二、机器学习\n",
    "\n",
    "机器学习是实现人工智能的一种手段，也是目前被认为比较有效的实现人工智能的手段，目前在业界使用机器学习比较突出的领域很多，例如：计算机视觉、自然语言处理、推荐系统等等。大家生活中经常用到的比如高速上的ETC的车牌识别，今日头条的新闻推荐，天猫上的评价描述。 \n",
    "机器学习是人工智能的一个分支，而在很多时候，几乎成为人工智能的代名词。简单来说，机器学习就是通过算法，使得机器能从大量历史数据中学习规律，从而对新的样本做智能识别或对未来做预测。\n",
    "\n",
    "\n",
    "## 2.1 人工智能vs机器学习\n",
    "> 人工智能是计算机科学的一个分支，研究计算机中智能行为的仿真。\n",
    "\n",
    "每当一台机器根据一组预先定义的解决问题的规则来完成任务时，这种行为就被称为人工智能。\n",
    "\n",
    "开发人员引入了大量计算机需要遵守的规则。计算机内部存在一个可能行为的具体清单，它会根据这个清单做出决定。如今，人工智能是一个概括性术语，涵盖了从高级算法到实际机器人的所有内容。\n",
    "\n",
    "我们有四个不同层次的AI，让我们来解释前两个:\n",
    "- 弱人工智能，也被称为狭义人工智能，是一种为特定的任务而设计和训练的人工智能系统。弱人工智能的形式之一是虚拟个人助理，比如苹果公司的Siri。\n",
    "- 强人工智能，又称人工通用智能，是一种具有人类普遍认知能力的人工智能系统。当计算机遇到不熟悉的任务时，它具有足够的智能去寻找解决方案。\n",
    "\n",
    "机器学习是指计算机使用大数据集而不是硬编码规则来学习的能力。\n",
    "\n",
    "机器学习允许计算机自己学习。这种学习方式利用了现代计算机的处理能力，可以轻松地处理大型数据集。\n",
    "\n",
    "基本上，机器学习是人工智能的一个子集;更为具体地说，它只是一种实现AI的技术，一种训练算法的模型，这种算法使得计算机能够学习如何做出决策。\n",
    "\n",
    "从某种意义上来说，机器学习程序根据计算机所接触的数据来进行自我调整。\n",
    "\n",
    "## 2.2 监督式学习vs非监督式学习\n",
    "> 监督式学习需要使用有输入和预期输出标记的数据集。\n",
    "\n",
    "当你使用监督式学习训练人工智能时，你需要提供一个输入并告诉它预期的输出结果。\n",
    "\n",
    "如果人工智能产生的输出结果是错误的，它将重新调整自己的计算。这个过程将在数据集上不断迭代地完成，直到AI不再出错。\n",
    "\n",
    "监督式学习的一个例子是天气预报人工智能。它学会利用历史数据来预测天气。训练数据包含输入(过去天气的压力、湿度、风速)和输出(过去天气的温度)。\n",
    "\n",
    "我们还可以想象您正在提供一个带有标记数据的计算机程序。例如，如果指定的任务是使用一种图像分类算法对男孩和女孩的图像进行分类，那么男孩的图像需要带有“男孩”标签，女孩的图像需要带有“女孩”标签。这些数据被认为是一个“训练”数据集，直到程序能够以可接受的速率成功地对图像进行分类，以上的标签才会失去作用。\n",
    "\n",
    "它之所以被称为监督式学习，是因为算法从训练数据集学习的过程就像是一位老师正在监督学习。在我们预先知道正确的分类答案的情况下，算法对训练数据不断进行迭代预测，然后预测结果由“老师”进行不断修正。当算法达到可接受的性能水平时，学习过程才会停止。\n",
    "\n",
    "> 非监督式学习是利用既不分类也不标记的信息进行机器学习，并允许算法在没有指导的情况下对这些信息进行操作。\n",
    "\n",
    "当你使用非监督式学习训练人工智能时，你可以让人工智能对数据进行逻辑分类。这里机器的任务是根据相似性、模式和差异性对未排序的信息进行分组，而不需要事先对数据进行处理。\n",
    "\n",
    "非监督式学习的一个例子是亚马逊等电子商务网站的行为预测AI。\n",
    "\n",
    "它将创建自己输入数据的分类，帮助亚马逊识别哪种用户最有可能购买不同的产品(交叉销售策略)。\n",
    "另一个例子是，程序可以任意地使用以下两种算法中的一种来完成男孩女孩的图像分类任务。一种算法被称为“聚类”，它根据诸如头发长度、下巴大小、眼睛位置等特征将相似的对象分到同一个组。另一种算法被称为“相关”，它根据自己发现的相似性创建if/then规则。换句话说，它确定了图像之间的公共模式，并相应地对它们进行分类。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 三、深度学习如何工作\n",
    "\n",
    "什么是深度学习，以及它是如何工作的。\n",
    "\n",
    "深度学习是一种机器学习方法 ， 它允许我们训练人工智能来预测输出，给定一组输入(指传入或传出计算机的信息)。监督学习和非监督学习都可以用来训练人工智能。\n",
    "\n",
    "> Andrew Ng：“与深度学习类似的是，火箭发动机是深度学习模型，燃料是我们可以提供给这些算法的海量数据。”\n",
    "\n",
    "我们将通过建立一个公交票价估算在线服务来了解深度学习是如何工作的。为了训练它，我们将使用监督学习方法。\n",
    "\n",
    "我们希望我们的巴士票价估价师使用以下信息/输入来预测价格:\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/8dfb449f950f479789c91dbe580367cb0c911078e61a45c0a45cb7fd402cfb9e)\n",
    "\n",
    "## 3.1 神经网络\n",
    "神经网络是一组粗略模仿人类大脑，用于模式识别的算法。神经网络这个术语来源于这些系统架构设计背后的灵感，这些系统是用于模拟生物大脑自身神经网络的基本结构，以便计算机能够执行特定的任务。 \n",
    "\n",
    "和人类一样， “AI价格评估”也是由神经元(圆圈)组成的。此外，这些神经元还是相互连接的。 \n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/24ba46820718419da5b164c55410fa871bc1dc870377440894dae3a77b85957d)\n",
    "\n",
    "神经元分为三种不同类型的层次：\n",
    "- 输入层接收输入数据。在我们的例子中，输入层有四个神经元:出发站、目的地站、出发日期和巴士公司。输入层会将输入数据传递给第一个隐藏层。\n",
    "\n",
    "- 隐藏层对输入数据进行数学计算。创建神经网络的挑战之一是决定隐藏层的数量，以及每一层中的神经元的数量。\n",
    "\n",
    "- 人工神经网络的输出层是神经元的最后一层，主要作用是为此程序产生给定的输出，在本例中输出结果是预测的价格值。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/5f0617e162a145ebafc97631534484a1e68e44b4b2374c299b06ed995ccc8c3b)\n",
    "\n",
    "神经元之间的每个连接都有一个权重。这个权重表示输入值的重要性。模型所做的就是学习每个元素对价格的贡献有多少。这些“贡献”是模型中的权重。一个特征的权重越高，说明该特征比其他特征更为重要。\n",
    "\n",
    "在预测公交票价时，出发日期是影响最终票价的最为重要的因素之一。因此，出发日期的神经元连接具有较大的“权重”。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/45ec203def6145c7948481834b56a34fcca2ea9a52a64397971b04ac43b87a92)\n",
    "\n",
    "每个神经元都有一个激活函数。它主要是一个根据输入传递输出的函数。\n",
    "当一组输入数据通过神经网络中的所有层时，最终通过输出层返回输出数据。\n",
    "\n",
    "## 3.2 通过训练改进神经网络\n",
    "\n",
    "为了提高“AI价格评估”的精度，我们需要将其预测结果与过去的结果进行比较，为此，我们需要两个要素:\n",
    "\n",
    "- 大量的计算能力；\n",
    "- 大量的数据。\n",
    "\n",
    "训练AI的过程中，重要的是给它的输入数据集(一个数据集是一个单独地或组合地或作为一个整体被访问的数据集合),此外还需要对其输出结果与数据集中的输出结果进行对比。因为AI一直是“新的”，它的输出结果有可能是错误的。\n",
    "\n",
    "对于我们的公交票价模型，我们必须找到过去票价的历史数据。由于有大量“公交车站”和“出发日期”的可能组合，因而我们需要一个非常大的票价清单。\n",
    "\n",
    "一旦我们遍历了整个数据集，就有可能创建一个函数来衡量AI输出与实际输出(历史数据)之间的差异。这个函数叫做成本函数。即成本函数是一个衡量模型准确率的指标，衡量依据为此模型估计X与Y间关系的能力。\n",
    "\n",
    "模型训练的目标是使成本函数等于零，即当AI的输出结果与数据集的输出结果一致时（成本函数等于0）。\n",
    "\n",
    "## 3.3 我们如何降低成本函数呢?\n",
    "\n",
    "通过使用一种叫做梯度下降的方法。梯度衡量得是，如果你稍微改变一下输入值，函数的输出值会发生多大的变化。\n",
    "\n",
    "梯度下降法是一种求函数最小值的方法。在这种情况下，目标是取得成本函数的最小值。\n",
    "它通过每次数据集迭代之后优化模型的权重来训练模型。通过计算某一权重集下代价函数的梯度，可以看出最小值的梯度方向。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/666c7aca1f69433490eb0a183e0b8dc7d79e9541f6d54d1985e3eba67f322c1d)\n",
    "\n",
    "为了降低成本函数值，多次遍历数据集非常重要。这就是为什么需要大量计算能力的原因。\n",
    "一旦我们通过训练改进了AI，我们就可以利用它根据上述四个要素来预测未来的价格。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 四、看看第一个例子吧！\n",
    "\n",
    "## 4.1 初识神经网络\n",
    "\n",
    "我们来看一个具体的神经网络示例，使用 PaddlePaddle来学习手写数字分类。如果你没用过PaddlePaddle或类似的库，可能无法立刻搞懂这个例子中的全部内容。甚至你可能还没有安装PaddlePaddle, 没关系，第四课会教大家如何安装PaddlePaddle，学会基本的命令和操作。因此，如果其中某些步骤看起来不太明白也不要担心。下面我们要开始了。\n",
    "\n",
    "我们这里要解决的问题是，将手写数字的灰度图像（28 像素×28 像素）划分到 10 个类别 中（0~9）。我们将使用 MNIST 数据集，它是机器学习领域的一个经典数据集，其历史几乎和这 个领域一样长，而且已被人们深入研究。这个数据集包含 60 000 张训练图像和 10 000 张测试图 像，由美国国家标准与技术研究院（National Institute of Standards and Technology，即 MNIST 中 的 NIST）在 20 世纪 80 年代收集得到。你可以将“解决”MNIST 问题看作深度学习的“Hello World”，正是用它来验证你的算法是否按预期运行。当你成为机器学习从业者后，会发现 MNIST 一次又一次地出现在科学论文、博客文章等中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step1:准备数据\n",
    "\n",
    "MINIST数据集包含60000个训练集和10000测试数据集。分为图片和标签，图片是28*28的像素矩阵，标签为0~9共10个数字。 2.定义读取MNIST数据集的train_reader和test_reader，指定一个Batch的大小为128，也就是一次训练或验证128张图像。 3.paddle.dataset.mnist.train()或test()接口已经为我们对图片进行了灰度处理、归一化、居中处理等处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[==================================================]t/train-images-idx3-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/train-images-idx3-ubyte.gz\n",
      "[==================================================]t/train-labels-idx1-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/train-labels-idx1-ubyte.gz\n",
      "[==================================================]t/t10k-images-idx3-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "[==================================================]t/t10k-labels-idx1-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#导入需要的包\n",
    "import numpy as np\n",
    "import paddle as paddle\n",
    "import paddle.fluid as fluid\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "train_reader = paddle.batch(paddle.reader.shuffle(paddle.dataset.mnist.train(),\n",
    "                                                  buf_size=512),\n",
    "                    batch_size=128)\n",
    "test_reader = paddle.batch(paddle.dataset.mnist.test(),\n",
    "                           batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "打印一下，观察一下mnist数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(array([-1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -0.9764706 , -0.85882354, -0.85882354,\n",
      "       -0.85882354, -0.01176471,  0.06666672,  0.37254906, -0.79607844,\n",
      "        0.30196083,  1.        ,  0.9372549 , -0.00392157, -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -0.7647059 , -0.7176471 , -0.26274508,  0.20784318,\n",
      "        0.33333337,  0.9843137 ,  0.9843137 ,  0.9843137 ,  0.9843137 ,\n",
      "        0.9843137 ,  0.7647059 ,  0.34901965,  0.9843137 ,  0.8980392 ,\n",
      "        0.5294118 , -0.4980392 , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -0.6156863 ,  0.8666667 ,\n",
      "        0.9843137 ,  0.9843137 ,  0.9843137 ,  0.9843137 ,  0.9843137 ,\n",
      "        0.9843137 ,  0.9843137 ,  0.9843137 ,  0.96862745, -0.27058822,\n",
      "       -0.35686272, -0.35686272, -0.56078434, -0.69411767, -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -0.85882354,  0.7176471 ,  0.9843137 ,  0.9843137 ,\n",
      "        0.9843137 ,  0.9843137 ,  0.9843137 ,  0.5529412 ,  0.427451  ,\n",
      "        0.9372549 ,  0.8901961 , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -0.372549  ,  0.22352946, -0.1607843 ,  0.9843137 ,  0.9843137 ,\n",
      "        0.60784316, -0.9137255 , -1.        , -0.6627451 ,  0.20784318,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -0.8901961 ,\n",
      "       -0.99215686,  0.20784318,  0.9843137 , -0.29411763, -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        ,  0.09019613,\n",
      "        0.9843137 ,  0.4901961 , -0.9843137 , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -0.9137255 ,  0.4901961 ,  0.9843137 ,\n",
      "       -0.45098037, -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -0.7254902 ,  0.8901961 ,  0.7647059 ,  0.254902  ,\n",
      "       -0.15294117, -0.99215686, -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -0.36470586,  0.88235295,  0.9843137 ,  0.9843137 , -0.06666666,\n",
      "       -0.8039216 , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -0.64705884,\n",
      "        0.45882356,  0.9843137 ,  0.9843137 ,  0.17647064, -0.7882353 ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -0.8745098 , -0.27058822,\n",
      "        0.9764706 ,  0.9843137 ,  0.4666667 , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        ,  0.9529412 ,  0.9843137 ,\n",
      "        0.9529412 , -0.4980392 , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -0.6392157 ,  0.0196079 ,\n",
      "        0.43529415,  0.9843137 ,  0.9843137 ,  0.62352943, -0.9843137 ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -0.69411767,\n",
      "        0.16078436,  0.79607844,  0.9843137 ,  0.9843137 ,  0.9843137 ,\n",
      "        0.9607843 ,  0.427451  , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -0.8117647 , -0.10588235,  0.73333335,  0.9843137 ,  0.9843137 ,\n",
      "        0.9843137 ,  0.9843137 ,  0.5764706 , -0.38823527, -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -0.81960785, -0.4823529 ,  0.67058825,  0.9843137 ,\n",
      "        0.9843137 ,  0.9843137 ,  0.9843137 ,  0.5529412 , -0.36470586,\n",
      "       -0.9843137 , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -0.85882354,  0.3411765 ,  0.7176471 ,\n",
      "        0.9843137 ,  0.9843137 ,  0.9843137 ,  0.9843137 ,  0.5294118 ,\n",
      "       -0.372549  , -0.92941177, -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -0.5686275 ,  0.34901965,\n",
      "        0.77254903,  0.9843137 ,  0.9843137 ,  0.9843137 ,  0.9843137 ,\n",
      "        0.9137255 ,  0.04313731, -0.9137255 , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        ,  0.06666672,  0.9843137 ,  0.9843137 ,  0.9843137 ,\n",
      "        0.6627451 ,  0.05882359,  0.03529418, -0.8745098 , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
      "       -1.        , -1.        , -1.        , -1.        ], dtype=float32), 5)]\n"
     ]
    }
   ],
   "source": [
    "temp_reader = paddle.batch(paddle.dataset.mnist.train(),\n",
    "                           batch_size=1)\n",
    "temp_data=next(temp_reader())\n",
    "print(temp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step2:配置网络\n",
    "\n",
    "以下的代码判断就是定义一个简单的多层感知器，一共有三层，两个大小为100的隐层和一个大小为10的输出层，因为MNIST数据集是手写0到9的灰度图像，类别有10个，所以最后的输出大小是10。最后输出层的激活函数是Softmax，所以最后的输出层相当于一个分类器。加上一个输入层的话，多层感知器的结构是：输入层-->>隐层-->>隐层-->>输出层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义多层感知器\n",
    "def multilayer_perceptron(input):\n",
    "    # 第一个全连接层，激活函数为ReLU\n",
    "    hidden1 = fluid.layers.fc(input=input, size=100, act='relu')\n",
    "    # 第二个全连接层，激活函数为ReLU\n",
    "    hidden2 = fluid.layers.fc(input=hidden1, size=100, act='relu')\n",
    "    # 以softmax为激活函数的全连接输出层，大小为10\n",
    "    prediction = fluid.layers.fc(input=hidden2, size=10, act='softmax')\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "定义输入层，输入的是图像数据。图像是2828的灰度图，所以输入的形状是[1, 28, 28]，如果图像是3232的彩色图，那么输入的形状是[3. 32, 32]，因为灰度图只有一个通道，而彩色图有RGB三个通道。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义输入输出层\n",
    "image = fluid.layers.data(name='image', shape=[1, 28, 28], dtype='float32')  #单通道，28*28像素值\n",
    "label = fluid.layers.data(name='label', shape=[1], dtype='int64')            #图片标签"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "在这里调用定义好的网络来获取分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 获取分类器\n",
    "model = multilayer_perceptron(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "接着是定义损失函数，这次使用的是交叉熵损失函数，该函数在分类任务上比较常用。定义了一个损失函数之后，还有对它求平均值，因为定义的是一个Batch的损失值。同时我们还可以定义一个准确率函数，这个可以在我们训练的时候输出分类的准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 获取损失函数和准确率函数\n",
    "cost = fluid.layers.cross_entropy(input=model, label=label)  #使用交叉熵损失函数,描述真实样本标签和预测概率之间的差值\n",
    "avg_cost = fluid.layers.mean(cost)\n",
    "acc = fluid.layers.accuracy(input=model, label=label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "接着是定义优化方法，这次我们使用的是Adam优化方法，同时指定学习率为0.001。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义优化方法\n",
    "optimizer = fluid.optimizer.AdamOptimizer(learning_rate=0.001)   #使用Adam算法进行优化\n",
    "opts = optimizer.minimize(avg_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step3:模型训练 & STEP4:模型评估\n",
    "\n",
    "接着也是定义一个解析器和初始化参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义一个使用CPU的解析器\n",
    "place = fluid.CPUPlace()\n",
    "exe = fluid.Executor(place)\n",
    "# 进行参数初始化\n",
    "exe.run(fluid.default_startup_program())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "输入的数据维度是图像数据和图像对应的标签，每个类别的图像都要对应一个标签，这个标签是从0递增的整型数值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义输入数据维度\n",
    "feeder = fluid.DataFeeder(place=place, feed_list=[image, label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "最后就可以开始训练了，我们这次训练5个Pass。在上面我们已经定义了一个求准确率的函数，所以我们在训练的时候让它输出当前的准确率，计算准确率的原理很简单，就是把训练是预测的结果和真实的值比较，求出准确率。每一个Pass训练结束之后，再进行一次测试，使用测试集进行测试，并求出当前的Cost和准确率的平均值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:0, Batch:0, Cost:2.70130, Accuracy:0.05469\n",
      "Pass:0, Batch:100, Cost:0.44905, Accuracy:0.84375\n",
      "Pass:0, Batch:200, Cost:0.20944, Accuracy:0.93750\n",
      "Pass:0, Batch:300, Cost:0.37832, Accuracy:0.85938\n",
      "Pass:0, Batch:400, Cost:0.21634, Accuracy:0.93750\n",
      "Test:0, Cost:0.22907, Accuracy:0.92880\n",
      "save models to /home/aistudio/data/hand.inference.model\n",
      "Pass:1, Batch:0, Cost:0.30485, Accuracy:0.91406\n",
      "Pass:1, Batch:100, Cost:0.20843, Accuracy:0.95312\n",
      "Pass:1, Batch:200, Cost:0.12292, Accuracy:0.96875\n",
      "Pass:1, Batch:300, Cost:0.12543, Accuracy:0.95312\n",
      "Pass:1, Batch:400, Cost:0.08486, Accuracy:0.97656\n",
      "Test:1, Cost:0.15316, Accuracy:0.95095\n",
      "save models to /home/aistudio/data/hand.inference.model\n",
      "Pass:2, Batch:0, Cost:0.21079, Accuracy:0.92969\n",
      "Pass:2, Batch:100, Cost:0.12976, Accuracy:0.95312\n",
      "Pass:2, Batch:200, Cost:0.08817, Accuracy:0.97656\n",
      "Pass:2, Batch:300, Cost:0.20444, Accuracy:0.94531\n",
      "Pass:2, Batch:400, Cost:0.11258, Accuracy:0.95312\n",
      "Test:2, Cost:0.11705, Accuracy:0.96222\n",
      "save models to /home/aistudio/data/hand.inference.model\n",
      "Pass:3, Batch:0, Cost:0.18898, Accuracy:0.95312\n",
      "Pass:3, Batch:100, Cost:0.14870, Accuracy:0.94531\n",
      "Pass:3, Batch:200, Cost:0.06573, Accuracy:0.97656\n",
      "Pass:3, Batch:300, Cost:0.11360, Accuracy:0.97656\n",
      "Pass:3, Batch:400, Cost:0.04338, Accuracy:0.98438\n",
      "Test:3, Cost:0.09820, Accuracy:0.96786\n",
      "save models to /home/aistudio/data/hand.inference.model\n",
      "Pass:4, Batch:0, Cost:0.11982, Accuracy:0.96875\n",
      "Pass:4, Batch:100, Cost:0.11513, Accuracy:0.97656\n",
      "Pass:4, Batch:200, Cost:0.06515, Accuracy:0.99219\n",
      "Pass:4, Batch:300, Cost:0.16725, Accuracy:0.96094\n",
      "Pass:4, Batch:400, Cost:0.09474, Accuracy:0.98438\n",
      "Test:4, Cost:0.08979, Accuracy:0.97083\n",
      "save models to /home/aistudio/data/hand.inference.model\n"
     ]
    }
   ],
   "source": [
    "# 开始训练和测试\n",
    "for pass_id in range(5):\n",
    "    # 进行训练\n",
    "    for batch_id, data in enumerate(train_reader()):                        #遍历train_reader\n",
    "        train_cost, train_acc = exe.run(program=fluid.default_main_program(),#运行主程序\n",
    "                                        feed=feeder.feed(data),             #给模型喂入数据\n",
    "                                        fetch_list=[avg_cost, acc])         #fetch 误差、准确率\n",
    "        # 每100个batch打印一次信息  误差、准确率\n",
    "        if batch_id % 100 == 0:\n",
    "            print('Pass:%d, Batch:%d, Cost:%0.5f, Accuracy:%0.5f' %\n",
    "                  (pass_id, batch_id, train_cost[0], train_acc[0]))\n",
    "\n",
    "    # 进行测试\n",
    "    test_accs = []\n",
    "    test_costs = []\n",
    "    #每训练一轮 进行一次测试\n",
    "    for batch_id, data in enumerate(test_reader()):                         #遍历test_reader\n",
    "        test_cost, test_acc = exe.run(program=fluid.default_main_program(), #执行训练程序\n",
    "                                      feed=feeder.feed(data),               #喂入数据\n",
    "                                      fetch_list=[avg_cost, acc])           #fetch 误差、准确率\n",
    "        test_accs.append(test_acc[0])                                       #每个batch的准确率\n",
    "        test_costs.append(test_cost[0])                                     #每个batch的误差\n",
    "    # 求测试结果的平均值\n",
    "    test_cost = (sum(test_costs) / len(test_costs))                         #每轮的平均误差\n",
    "    test_acc = (sum(test_accs) / len(test_accs))                            #每轮的平均准确率\n",
    "    print('Test:%d, Cost:%0.5f, Accuracy:%0.5f' % (pass_id, test_cost, test_acc))\n",
    "    \n",
    "    #保存模型\n",
    "    model_save_dir = \"/home/aistudio/data/hand.inference.model\"\n",
    "    # 如果保存路径不存在就创建\n",
    "    if not os.path.exists(model_save_dir):\n",
    "        os.makedirs(model_save_dir)\n",
    "    print ('save models to %s' % (model_save_dir))\n",
    "    fluid.io.save_inference_model(model_save_dir,  #保存推理model的路径\n",
    "                                  ['image'],      #推理（inference）需要 feed 的数据\n",
    "                                  [model],        #保存推理（inference）结果的 Variables\n",
    "                                  exe)            #executor 保存 inference model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step5:模型预测\n",
    "\n",
    "在预测之前，要对图像进行预处理，处理方式要跟训练的时候一样。首先进行灰度化，然后压缩图像大小为28*28，接着将图像转换成一维向量，最后再对一维向量进行归一化处理。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 对图片进行预处理\n",
    "def load_image(file):\n",
    "    im = Image.open(file).convert('L')                        #将RGB转化为灰度图像，L代表灰度图像，灰度图像的像素值在0~255之间\n",
    "    im = im.resize((28, 28), Image.ANTIALIAS)                 #resize image with high-quality 图像大小为28*28\n",
    "    im = np.array(im).reshape(1, 1, 28, 28).astype(np.float32)#返回新形状的数组,把它变成一个 numpy 数组以匹配数据馈送格式。\n",
    "   # print(im)\n",
    "    im = im / 255.0 * 2.0 - 1.0                               #归一化到【-1~1】之间\n",
    "    print(im)\n",
    "    return im\n",
    "\n",
    "img = Image.open('data/data27012/6.png')\n",
    "plt.imshow(img)   #根据数组绘制图像\n",
    "plt.show()        #显示图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "infer_exe = fluid.Executor(place)\n",
    "inference_scope = fluid.core.Scope()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "最后把图像转换成一维向量并进行预测，数据从feed中的image传入。fetch_list的值是网络模型的最后一层分类器，所以输出的结果是10个标签的概率值，这些概率值的总和为1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-0.9843137  -0.9843137  -0.9843137  -0.9843137  -0.9843137\n",
      "    -0.9843137  -0.9843137  -0.9843137  -0.9843137  -0.9843137\n",
      "    -0.9843137  -0.9843137  -0.9843137  -0.9843137  -0.9843137\n",
      "    -0.9843137  -0.9843137  -0.9607843  -0.8980392  -0.9764706\n",
      "    -0.99215686 -0.96862745 -1.         -1.         -0.96862745\n",
      "    -0.9607843  -0.99215686 -0.9843137 ]\n",
      "   [-0.9843137  -0.9843137  -0.9843137  -0.9843137  -0.9843137\n",
      "    -0.9843137  -0.9843137  -0.9843137  -0.9843137  -0.9843137\n",
      "    -0.9843137  -0.9843137  -0.9843137  -0.9843137  -0.9843137\n",
      "    -0.9843137  -0.9843137  -0.9764706  -0.94509804 -0.9372549\n",
      "    -1.         -0.9843137  -0.19215685 -0.19999999 -0.7882353\n",
      "    -0.9843137  -0.9764706  -0.9843137 ]\n",
      "   [-0.9843137  -0.9843137  -0.9843137  -0.9843137  -0.9843137\n",
      "    -0.9843137  -0.9843137  -0.9843137  -0.9843137  -0.9843137\n",
      "    -0.9843137  -0.9843137  -0.9843137  -0.9843137  -0.9843137\n",
      "    -0.9843137  -0.9843137  -1.         -1.         -0.9529412\n",
      "    -0.9372549  -0.6862745   0.654902    0.654902   -0.54509807\n",
      "    -1.         -0.96862745 -0.9843137 ]\n",
      "   [-0.9843137  -0.9843137  -0.9843137  -0.9843137  -0.9843137\n",
      "    -0.9843137  -0.9843137  -0.9843137  -0.9843137  -0.9843137\n",
      "    -0.9843137  -0.9843137  -0.9843137  -0.9843137  -0.9843137\n",
      "    -0.99215686 -0.9529412  -0.8509804  -0.9529412  -1.\n",
      "    -0.94509804  0.00392163  0.81960785 -0.05098039 -0.8352941\n",
      "    -0.9843137  -0.9764706  -0.9843137 ]\n",
      "   [-0.9843137  -0.9843137  -0.9843137  -0.9843137  -0.9843137\n",
      "    -0.9843137  -0.9843137  -0.9843137  -0.9843137  -0.9843137\n",
      "    -0.9843137  -0.9843137  -0.9843137  -0.9843137  -0.9843137\n",
      "    -0.9843137  -0.96862745 -0.88235295 -0.84313726 -0.7411765\n",
      "    -0.1372549   0.6156863   0.09803927 -0.7882353  -1.\n",
      "    -0.96862745 -0.9843137  -0.9843137 ]\n",
      "   [-0.9843137  -0.9843137  -0.9843137  -0.9843137  -0.9843137\n",
      "    -0.9843137  -0.9843137  -0.9843137  -0.9843137  -0.9843137\n",
      "    -0.9843137  -0.9843137  -0.9843137  -0.9843137  -0.9843137\n",
      "    -0.9843137  -0.96862745 -0.94509804 -0.92156863 -0.19999999\n",
      "     0.827451    0.5764706  -0.78039217 -0.9529412  -0.94509804\n",
      "    -0.99215686 -0.9843137  -0.9843137 ]\n",
      "   [-0.9843137  -0.9843137  -0.9843137  -0.9843137  -0.9843137\n",
      "    -0.9843137  -0.9843137  -0.9843137  -0.9843137  -0.9843137\n",
      "    -0.9843137  -0.9843137  -0.9843137  -0.9843137  -0.9843137\n",
      "    -0.9764706  -0.9529412  -0.88235295 -0.38823527  0.6156863\n",
      "     0.4039216  -0.40392154 -0.9137255  -0.9529412  -0.99215686\n",
      "    -1.         -0.9843137  -0.9843137 ]\n",
      "   [-0.9843137  -0.9843137  -0.9843137  -0.9843137  -0.9843137\n",
      "    -0.9843137  -0.9843137  -0.9843137  -0.9843137  -0.99215686\n",
      "    -0.99215686 -0.99215686 -0.99215686 -0.9764706  -0.9607843\n",
      "    -0.9843137  -1.         -0.5294118   0.67058825  0.5921569\n",
      "    -0.5372549  -1.         -0.92156863 -0.96862745 -0.9764706\n",
      "    -0.9764706  -0.9843137  -0.9843137 ]\n",
      "   [-0.9843137  -0.9843137  -0.9843137  -0.9843137  -0.9843137\n",
      "    -0.9843137  -0.9843137  -0.9843137  -0.9843137  -1.\n",
      "    -0.99215686 -0.96862745 -0.9764706  -1.         -0.9529412\n",
      "    -0.8509804  -0.60784316  0.28627455  0.7019608  -0.2862745\n",
      "    -0.9607843  -0.9843137  -0.9607843  -0.9843137  -0.9607843\n",
      "    -0.96862745 -0.99215686 -0.9843137 ]\n",
      "   [-0.9843137  -0.9843137  -0.9843137  -0.9843137  -0.9843137\n",
      "    -0.9843137  -0.9843137  -0.9843137  -1.         -0.9764706\n",
      "    -0.9764706  -0.9607843  -0.92941177 -0.92941177 -0.81960785\n",
      "    -0.31764704  0.4431373   0.5921569  -0.2235294  -0.77254903\n",
      "    -0.9607843  -0.9529412  -0.99215686 -0.9529412  -0.9764706\n",
      "    -1.         -0.9843137  -0.9843137 ]\n",
      "   [-0.9843137  -0.9843137  -0.9843137  -0.9843137  -0.9843137\n",
      "    -0.9843137  -0.9843137  -0.9843137  -0.9764706  -0.96862745\n",
      "    -0.9607843  -0.9607843  -0.94509804 -0.75686276 -0.26274508\n",
      "     0.45098042  0.7882353  -0.15294117 -0.85882354 -0.8352941\n",
      "    -0.8980392  -0.9372549  -0.9843137  -0.8980392  -0.9607843\n",
      "    -1.         -0.9843137  -0.9843137 ]\n",
      "   [-0.9843137  -0.9843137  -0.9843137  -0.9843137  -0.9843137\n",
      "    -0.9843137  -0.9843137  -0.9843137  -0.92941177 -0.96862745\n",
      "    -0.90588236 -0.9137255  -0.9607843  -0.3333333   0.6313726\n",
      "     0.69411767 -0.15294117 -0.9372549  -1.         -0.827451\n",
      "    -0.9137255  -0.9607843  -0.99215686 -0.9529412  -0.9607843\n",
      "    -0.9764706  -0.9843137  -0.9843137 ]\n",
      "   [-0.9843137  -0.9843137  -0.9843137  -0.9843137  -0.9843137\n",
      "    -0.9843137  -0.9843137  -0.9843137  -0.99215686 -0.94509804\n",
      "    -0.96862745 -0.9137255  -0.34117645  0.48235297  0.58431375\n",
      "    -0.18431371 -0.827451   -0.8039216  -0.9137255  -0.99215686\n",
      "    -0.9607843  -0.8901961  -0.9764706  -1.         -0.94509804\n",
      "    -0.9529412  -0.99215686 -0.9843137 ]\n",
      "   [-0.9843137  -0.9843137  -0.9843137  -0.9843137  -0.9843137\n",
      "    -0.9843137  -0.9843137  -0.9843137  -0.9372549  -0.9764706\n",
      "    -0.9529412  -0.20784312  0.8666667   0.58431375 -0.42745095\n",
      "    -0.5137255   0.2941177   0.17647064 -0.14509803 -0.5921569\n",
      "    -0.8901961  -0.90588236 -0.96862745 -0.92941177 -0.96862745\n",
      "    -0.99215686 -0.9843137  -0.9843137 ]\n",
      "   [-0.9843137  -0.9843137  -0.9843137  -0.9843137  -0.9843137\n",
      "    -0.9843137  -0.9843137  -0.9843137  -0.9843137  -0.9529412\n",
      "    -0.3960784   0.54509807  0.94509804  0.67058825  0.5137255\n",
      "     0.7019608   0.8509804   0.8039216   0.8745098   0.39607847\n",
      "    -0.7647059  -1.         -0.94509804 -0.8666667  -0.9529412\n",
      "    -1.         -0.9843137  -0.9843137 ]\n",
      "   [-0.9843137  -0.9843137  -0.9843137  -0.9843137  -0.9843137\n",
      "    -0.9764706  -0.9764706  -0.9764706  -0.9529412  -0.24705881\n",
      "     0.6392157   0.9843137   0.8745098   0.8745098   0.88235295\n",
      "     0.3803922  -0.27843136  0.09019613  0.92156863  0.84313726\n",
      "    -0.7254902  -0.99215686 -0.85882354 -0.9137255  -0.9843137\n",
      "    -0.99215686 -0.9843137  -0.9843137 ]\n",
      "   [-0.9843137  -0.99215686 -0.9764706  -0.9529412  -0.8980392\n",
      "    -0.8509804  -0.8509804  -0.92941177 -0.5058824   0.5058824\n",
      "     0.9529412   0.8901961   0.49803925 -0.10588235 -0.5058824\n",
      "    -0.7490196  -0.8980392  -0.3333333   0.8509804   0.34901965\n",
      "    -0.6156863  -0.8039216  -0.92941177 -0.96862745 -0.9372549\n",
      "    -0.9607843  -0.99215686 -0.9843137 ]\n",
      "   [-0.9372549  -0.9372549  -0.96862745 -0.99215686 -0.9843137\n",
      "    -0.94509804 -0.9607843  -0.94509804  0.26274514  0.96862745\n",
      "     0.827451   -0.01176471 -0.77254903 -0.92156863 -0.9607843\n",
      "    -0.92941177 -0.81960785  0.37254906  0.654902   -0.23921567\n",
      "    -0.90588236 -0.96862745 -0.9843137  -0.9372549  -0.9529412\n",
      "    -0.9843137  -0.9843137  -0.9843137 ]\n",
      "   [-0.9843137  -0.96862745 -0.96862745 -0.9764706  -0.9764706\n",
      "    -0.8745098  -0.84313726 -0.19999999  0.60784316  0.5058824\n",
      "    -0.11372548 -0.70980394 -0.92941177 -0.8901961  -1.\n",
      "    -0.7254902   0.20784318  0.6313726   0.07450986 -0.7176471\n",
      "    -1.         -1.         -0.9607843  -0.8980392  -0.9607843\n",
      "    -1.         -0.9843137  -0.9843137 ]\n",
      "   [-0.9843137  -1.         -0.96862745 -0.8901961  -0.96862745\n",
      "    -0.9607843  -0.8352941   0.4901961   0.92941177 -0.30196077\n",
      "    -1.         -0.92156863 -1.         -0.8666667  -0.17647058\n",
      "     0.56078434  0.73333335  0.03529418 -0.60784316 -0.9372549\n",
      "    -0.9372549  -0.9607843  -0.9843137  -0.9607843  -0.9843137\n",
      "    -1.         -0.9843137  -0.9843137 ]\n",
      "   [-0.9529412  -1.         -0.9764706  -0.88235295 -0.9843137\n",
      "    -1.         -0.9372549   0.49803925  0.99215686  0.45882356\n",
      "     0.26274514  0.3411765   0.18431377  0.34901965  0.827451\n",
      "     0.88235295  0.24705887 -0.654902   -0.9372549  -0.92941177\n",
      "    -0.9137255  -0.96862745 -1.         -1.         -0.9529412\n",
      "    -0.9607843  -0.99215686 -0.9843137 ]\n",
      "   [-0.9764706  -0.99215686 -0.99215686 -0.9607843  -0.9607843\n",
      "    -0.9137255  -0.9372549  -0.05882353  0.6784314   1.\n",
      "     1.          1.          0.8352941   0.38823533  0.05882359\n",
      "    -0.52156866 -0.8039216  -0.9843137  -0.99215686 -0.9529412\n",
      "    -0.9843137  -0.9764706  -0.9372549  -0.9843137  -0.94509804\n",
      "    -0.9529412  -0.99215686 -0.9843137 ]\n",
      "   [-0.9764706  -0.96862745 -0.9843137  -1.         -0.9843137\n",
      "    -0.92156863 -0.96862745 -0.73333335 -0.47450978 -0.36470586\n",
      "    -0.38039213 -0.32549018 -0.41176468 -0.6784314  -0.81960785\n",
      "    -0.8901961  -1.         -1.         -0.9843137  -0.99215686\n",
      "    -1.         -0.92156863 -0.8745098  -0.92941177 -0.9607843\n",
      "    -0.9764706  -0.9843137  -0.9843137 ]\n",
      "   [-0.9843137  -0.9764706  -0.9529412  -0.9843137  -1.\n",
      "    -0.9607843  -0.96862745 -1.         -1.         -1.\n",
      "    -1.         -1.         -0.9137255  -0.85882354 -0.9372549\n",
      "    -0.8980392  -0.9764706  -0.99215686 -0.9843137  -1.\n",
      "    -0.9607843  -0.9372549  -0.94509804 -0.9137255  -0.94509804\n",
      "    -0.9843137  -0.9843137  -0.9843137 ]\n",
      "   [-0.99215686 -0.99215686 -0.9607843  -0.9764706  -0.9843137\n",
      "    -0.96862745 -0.96862745 -0.9843137  -0.96862745 -0.9137255\n",
      "    -0.9137255  -0.92941177 -0.85882354 -0.8352941  -0.94509804\n",
      "    -1.         -0.9843137  -0.9843137  -0.9843137  -0.99215686\n",
      "    -0.96862745 -0.9843137  -1.         -0.9607843  -0.96862745\n",
      "    -0.9843137  -0.99215686 -0.99215686]\n",
      "   [-0.9843137  -0.9843137  -0.9843137  -0.9843137  -0.9843137\n",
      "    -0.9843137  -0.9843137  -0.9843137  -1.         -1.\n",
      "    -1.         -0.9764706  -0.99215686 -0.99215686 -1.\n",
      "    -1.         -1.         -0.99215686 -0.99215686 -0.99215686\n",
      "    -1.         -0.99215686 -0.99215686 -1.         -0.99215686\n",
      "    -0.99215686 -0.99215686 -0.99215686]\n",
      "   [-0.9843137  -0.9843137  -0.9843137  -0.9843137  -0.9843137\n",
      "    -0.9843137  -0.9843137  -0.9843137  -1.         -1.\n",
      "    -0.99215686 -0.9764706  -0.9764706  -0.96862745 -0.99215686\n",
      "    -1.         -1.         -0.99215686 -0.99215686 -0.99215686\n",
      "    -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "    -0.99215686 -0.99215686 -0.99215686]\n",
      "   [-0.9843137  -0.9843137  -0.9843137  -0.9843137  -0.9843137\n",
      "    -0.9843137  -0.9843137  -0.9843137  -1.         -1.\n",
      "    -0.99215686 -0.9764706  -0.9764706  -0.9764706  -0.99215686\n",
      "    -1.         -1.         -0.99215686 -0.99215686 -0.99215686\n",
      "    -0.99215686 -0.99215686 -0.99215686 -0.99215686 -0.99215686\n",
      "    -0.99215686 -0.99215686 -0.99215686]]]]\n"
     ]
    }
   ],
   "source": [
    "# 加载数据并开始预测\n",
    "with fluid.scope_guard(inference_scope):\n",
    "    #获取训练好的模型\n",
    "    #从指定目录中加载 推理model(inference model)\n",
    "    [inference_program,                                           #推理Program\n",
    "     feed_target_names,                                           #是一个str列表，它包含需要在推理 Program 中提供数据的变量的名称。 \n",
    "     fetch_targets] = fluid.io.load_inference_model(model_save_dir,#fetch_targets：是一个 Variable 列表，从中我们可以得到推断结果。model_save_dir：模型保存的路径\n",
    "                                                    infer_exe)     #infer_exe: 运行 inference model的 executor\n",
    "    img = load_image('data/data27012/6.png')\n",
    "\n",
    "    results = exe.run(program=inference_program,     #运行推测程序\n",
    "                   feed={feed_target_names[0]: img}, #喂入要预测的img\n",
    "                   fetch_list=fetch_targets)         #得到推测结果,    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "拿到每个标签的概率值之后，我们要获取概率最大的标签，并打印出来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "该图片的预测结果的label为: 6\n"
     ]
    }
   ],
   "source": [
    "# 获取概率最大的label\n",
    "lab = np.argsort(results)                               #argsort函数返回的是result数组值从小到大的索引值\n",
    "#print(lab)\n",
    "print(\"该图片的预测结果的label为: %d\" % lab[0][0][-1])  #-1代表读取数组中倒数第一列  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 五、总结\n",
    "到这里是不是觉得深度学习非常神奇呢？它具体是怎么实现的呢？背后有什么数学原理？在了解数学原理之前，先学习一下深度学习中常见的数学知识，第二节课就会带领大家学习必备的数学知识~"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.7.2 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
